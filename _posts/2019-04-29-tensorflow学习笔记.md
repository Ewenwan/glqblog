- padding的valid和same：https://www.cnblogs.com/willnote/p/6746668.html

- tf.nn.conv2d和tf.layers.conv2d区别：https://blog.csdn.net/touch_dream/article/details/78446850

- tf.train优化器：https://blog.csdn.net/xierhacker/article/details/53174558、https://www.jianshu.com/p/d99b83f4c1a6

  - tf.train.Optimizer：基类，用不到
  - tf.train.GradientDescentOptimizer：梯度下降

  

  - tf.train.AdagradOptimizer：Adagrad算法
  - tf.train.AdadeltaOptimizer：Adadelta算法，Adagrad算法的改进版本。 

  - tf.train.AdagradDAOptimizer：

  

  - tf.train.MomentumOptimizer：Momentum算法
  - tf.train.AdamOptimizer：Adam算法
  - tf.train.FtrlOptimizer
  - tf.train.ProximalGradientDescentOptimizer
  - tf.train.ProximalAdagradOptimizer
  - tf.train.RMSPropOptimizer

- session与InteractiveSession ：https://blog.csdn.net/qq_14839543/article/details/77822916

- tf.multipy()、tf.matmul()、tf.scalar_mul()区别：

  - http://www.mamicode.com/info-detail-2295769.html
  - https://www.jianshu.com/p/2a83eac1e35e

- 交叉熵函数区别：