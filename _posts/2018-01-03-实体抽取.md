---
    author: LuckyGong
    comments: true
    date: 2018-01-03 15:27
    layout: post
    title: 实体抽取
    categories:
    - nlp
    tags:
    - nlp
---

# 1.定义

- 狭义：人名、机构、地名
- 广义：时间、日期、数量表达式、金钱等
- 一般：人名、机构名、地名、时间、日期、货币和百分比 
- 子任务：实体边界识别、确定实体类别（和分词、词性标注有点像）

# 2.特点

- 时间、日期、货币和百分比的构成有比较明显的规律，识别起来相对容易

- 人名、地名、机构名的用字灵活，识别的难度很大

  - 在不同领域、 场景下, 命名实体的外延有差异 。
  - 数量巨大,不能枚举,难以全部收录在词典中。
  - 某些类型的实体名称变化频繁,并且没有严格的规律可以遵循。
  - 表达形式多样。
  - 首次出现后往往采用缩写形式。 

- **中文人名识别**

  - 由于英文本身有明显特征（如大小写），且不存在切分造成的错误，NER在英文中已得到很好的研究

  ​

  - 名字用字范围广，分布松散，规律不很明显 
  - 姓氏和名字都可以单独使用用于特指某一人（如：王二小，小王，二小）
  - 许多姓氏用字和名字用字(词)可以作为普通用字或词被使用
  - 缺乏可利用的启发标记（人名与其上下文组合成词） （如：祝贺老总百战百胜 ）
  - 中国人名各组成部分用字比较有规律：400个字占了90%的人名用字

- ***中文地名识别***

  - 地名数量大，缺乏明确、规范的定义。 
  - 真实语料中地名出现情况复杂。如地名简称、地名用词与其他普通词冲突、地名是其他专用名词的一部分，地名长度不一等。

- **中文机构名识别**

  - 机构名中含有大量的人名、地名、企业字号等专有名称。在这些专有名称中，地名所占的比例最大，其中未登录地名又占了相当一部分的比例。所以机构名识别应在人名、地名等其他专名识别之后进行，其他专名识别的正确率对机构名识别正确率有较大影响。 
  - 用词广泛。 
  - 机构名长度极其不固定 。
  - 机构名很不稳定。随着社会发展，新机构不断涌现，旧机构不断被淘汰、改组或更名 

  ​

- **音译名识别**

  - 用字非常集中 
  - 音译名内部很难划分出结构，但有一些常见音节，如“斯基、斯坦”等 
  - 不同语言的音译规律不尽相同，如法语、俄语、蒙古语译名用字与英语就有较大区别（蒙语人名举例：“那顺乌日图、青格勒图”），如果按不同的语言训练不同的模型可能会比使用统一的模型效果更好 
  - 音译名可以是人名、地名或其他专名，上下文规律差别较大 

# 3.方法

## 3.1基于词典

- 正向最大匹配法
- 反向最大匹配法
- 最短路径法（最少分词法） 

## 3.2基于规则

- **中文人名识别**
  - 中国人名一般由以下部分组合而成： 姓、名、前缀、后缀
  - 除此之外，还有：
    - 身份词：
      - 前：工人、教师、影星、犯人
      - 后：先生、同志
      - 前后：女士、教授、经理、小姐、总理 
    - 地名或机构名：前：静海县大丘庄禹作敏 
    - 的字结构：前：年过七旬的王贵芝 
    - 动作词： 前：批评，逮捕，选举；后：说，表示，吃，结婚 
- **中文地名识别**
  - 地名中使用的多字词中绝大部分是两个字 （山口 、水库、遗址）
  -  经常与方位词和介词连用（东、南、周边、附近、在、于）
- **中文机构名识别**
  - 词法角度：偏正式(修饰格式)的复合词，{名词|形容词|数量词|动词} + 名词 
  - 句法角度：“定语＋名词性中心语”型的名词短语(定名型短语) 
  - 中心语：机构称呼词，如：大学，学院，研究所，学会，公司，股份公司等 

## 3.3基于统计

### 3.3.1生成式

#### 3.3.1.1HMM

#### 3.3.1.2PCFG

### 3.3.2判别式

#### 3.3.2.1Maxent

#### 3.3.2.2SVM

#### 3.3.2.3CRF

- 开源工具：python-crfsuite
- 特征函数：可以构建不同种类的特征
  - 上下文特征：{yi-1= B-LOC，yi= I-LOC，xi-2=是，i=6}、{yi-1= #，yi= I-LOC，xi-2=是，i=6}
  - 词性特征：{xi-2=v，i=6}{xi-1=n，i=6} {x0=n，i=6}
  - 词表特征：{xi-1xi=1，i=6} 
- 参数训练
  - 对训练语料库中每句话生成一个实例
  - 把所有实例的列表送给CRF模型的训练工具
  - CRF的训练工具将学习到模型的参数（每个特征的权重） 
- 测试 
  - 对于输入串整体作为一个实例
  - 对这每个实例，生成其所有激活的特征，计算这些特征所对应的概率
  - 选取可能性最大的标记序列为该句子的标记 

#### 3.3.2.4CNN

#### 3.3.2.5RNN

#### 3.3.2.6LSTM+CRF（Lample NAACL16） 

##### 3.3.2.6.1动机

- 语言领域内资源或特征的获取耗时耗力（例如地理资源集gazetteers），避免使用语言领域内的资源或特征 
- 大多数领域内的命名实体识别标注语料很少，但是存在很多未标注语料，为了在少量的标注语料上取得较好的效果 
- 传统的特征提起过程中会用到复杂的NLP工具，会造成误差传递 

##### 3.3.2.6.2特征

- LSTM学习得到的特征相当于传统的CRF中的状态特征S（yi|x） 
- 词级别特征：每个词的词向量作为词的表示。
- 字符级别特征：通过将每个词拆成字符序列，通过双向LSTM得到该词的表示，将两种表示结合。

##### 3.3.2.6.3模型

- 每个词对应的LSTM输出为包含该词语实体类别信息的k维向量（k为实体tag的个数，n为词的数目），拼接成矩阵P（k*n），作为CRF中特征矩阵输入：

![](http://ot0qvixbu.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20180228110645.png)

![](http://ot0qvixbu.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20180228110902.png)

- 由转移概率矩阵A（标签i转移到标签j的概率）和特征矩阵P构成的得分函数，即为CRF的特征函数。对每一个句子序列X，给定任意一组标签Y，通过特征得分函数S计算条件概率，进而通过对条件概率求log似然得到目标函数，进行联合训练，同时优化LSTM与CRF的参数。

![](http://ot0qvixbu.bkt.clouddn.com/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20180228111043.png)

- 训练得到模型参数后，在该参数条件下，对于一给定句子序列X，使 得分最高的标签序列Y就为该句子序列的实体标签序列Y 

#### 3.3.2.7汉语分词与实体识别联合模型（PengACL16） 

##### 3.3.2.7.1动机

- 词边界能提供实体类别的有用信息，所以将词边界信息融入到命名实体识别中
-  汉语分词困难，与英语相比较分词准确率低，先分词，后实体识别，分词时的误差会传递到实体识别中，所以将分词与实体识别联合训练 

##### 3.3.2.7.2模型

- LSTM+CRF
- 将句子序列输入特征提取器中，得到词汇特征；分词阶段LSTM隐层输出得到分词特征；分词阶段词向量为词语特征，三个特征融合为CRF的总特征 。
- 分词和实体识别分别定义损失函数，最后将两个损失函数融合，实现两个任务的联合学习 

#### 3.3.2.8基于词典跨语言命名实体识别（Mayhew EMNLP17） 

##### 3.3.2.8.1动机

- 不同语言实体识别的标注语料资源丰富程度差别很大，寻找一种简单通用的多语言实体识别模型 
- 多语言实体识别任务中平行语料标注耗时耗力，寻找到一种“廉价”的基于多语言词典的实体识别模型 

##### 3.3.2.8.2算法

- 英语和土耳其语举例 
- 通过简单的词-词，词-短语，短语-短语翻译，将两语言词典对齐，再通过显著性得分（prominence）进行消歧，从而得到双语对齐词典。
- 得到对齐词典之后，给定一土耳其语句子，将句子中的词和短语通过词典匹配翻译，得到英语句子，虽然语序有时候问题，但是与实体相关的词和短语能准确的识别出来 

### 3.3.3对比

- HMM利用转移矩阵和生成矩阵建模相邻状态的转移概率和状态到观察的生成概率。 无法利用复杂特征（只有两个矩阵建模） 
- 最大熵可以使用任意的复杂特征（特征函数），但是ME只能建模观察序列和某一状态的关系，状态之间的关系无法得到充分利用。 
- CRF可以使用任意的复杂特征（特征函数）（虽然每个位置有一个矩阵，但是矩阵的元素是由特征函数和权重计算得到，我们可以任意地定义特征函数从而考虑各种特征），可以建模观察序列和多个状态的关系，考虑了状态之间的关系。 

# 4.评测与会议

- 国际会议：MUC、 SigHAN、 CoNLL、 IEER 和ACE 
- 许多英语命名实体系统已经具备了相当程度的大规模文本处理能力，但是中文还差强人意。

# 5.常用工具

1. BosonNLP
2. IKAnalyzer
3. NLPIR
4. SCWS
5. 结巴分词
6. 盘古分词
7. 庖丁解牛
8. 搜狗分词
9. 腾讯文智
10. 新浪云
11. 语言云

# 6.开放域实体抽取

## 6.1定义

不限定实体类别，不限定目标文本，给定某一类别的实体实例，从网页中抽取同一类别其他实体实例。

如：给出<中国，美国，俄罗斯>（称为“种子”），找出其他国家<德国，英国，法国……>。

## 6.2思路

种子词与目标词在网页中具有相同或者类似的上下文。

## 6.3流程

种子->抽取器（抽取模块）->候选->打分器（计算候选置信度）->结果

## 6.4方法

### 6.4.1Query Log (Pasca CIKM 2007) 

- 通过分析种子实例在查询日志中的上下文学得模板，再利用模板找到同类别的实例 
- 构造候选与种子上下文向量，计算相似度 

### 6.4.2Web Page (Wang ICDM 2007)  

- 处理列表型网页，在列表中，种子与目标实体具有相同的网页结构 

### 6.4.3融合多个数据源（Pennacchiotti EMNLP 2009 ）

- 针对不同数据源，选取不同特征分别进行实例扩展，对结果进行融合 
- 针对不同数据源选取不同的模板和特征 
- 使用不同特征计算候选的置信度 